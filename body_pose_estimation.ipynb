{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_first_frame(path, use_cv2=True):\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if use_cv2:\n",
    "        cv2.imshow('First Frame', frame)\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    else:\n",
    "        new_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(new_frame)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './data/videos/rcpc_bimbambum.mp4'\n",
    "# img = extract_video_first_frame(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_file = './openpose/openpose-master/models/pose/coco/pose_deploy_linevec.prototxt'\n",
    "weight_file = './openpose/openpose-master/models/pose/coco/pose_iter_440000.caffemodel'\n",
    "\n",
    "img = cv2.imread('./data/basketball.jpg')\n",
    "img_copy = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width, frame_height = img.shape[1], img.shape[0]\n",
    "in_height = 368\n",
    "in_width = 368\n",
    "\n",
    "pose_net = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "pose_blob = cv2.dnn.blobFromImage(img_copy, scalefactor=1.0/255, size=(in_width, in_height), mean=(0,0,0), swapRB=False, crop=False)\n",
    "pose_net.setInput(pose_blob)\n",
    "output = pose_net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "prob_map = output[0,i,:,:]\n",
    "prob_map = cv2.resize(prob_map, (frame_width, frame_height))\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))    \n",
    "plt.imshow(prob_map, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "map_gauss = cv2.GaussianBlur(prob_map, (3,3), 0, 0)\n",
    "map_mask = np.uint8(map_gauss > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(map_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "body_points = []\n",
    "\n",
    "for c in contours:\n",
    "    blob_mask = np.zeros(map_mask.shape)\n",
    "    blob_mask = cv2.fillConvexPoly(blob_mask, c, 1)\n",
    "    masked_prob_map = map_gauss * blob_mask\n",
    "    _, max_val, _, max_loc = cv2.minMaxLoc(masked_prob_map)\n",
    "    \n",
    "    body_points.append(max_loc + (prob_map[max_loc[1], max_loc[0]],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(body_points)):\n",
    "    cv2.circle(img_copy, (body_points[i][0], body_points[i][1]), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "cv2.imshow('Body Points', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_copy = img.copy()\n",
    "n_points = 18\n",
    "key_points_mapping = ['Nose', 'Neck', 'R-Shoulder', 'R-Elbow', 'R-Wrist', 'L-Shoulder', 'L-Elbow', 'L-Wrist', 'R-Hip', 'R-Knee', 'R-Ankle',\n",
    "                     'L-Hip', 'L-Knee', 'L-Ankle', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
    "\n",
    "\n",
    "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
    "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
    "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
    "              [2,17], [5,16]]\n",
    "\n",
    "# index of pafs correspoding to the POSE_PAIRS\n",
    "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44],\n",
    "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30],\n",
    "          [47,48], [49,50], [53,54], [51,52], [55,56],\n",
    "          [37,38], [45,46]]\n",
    " \n",
    "colors = [[0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
    "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
    "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_points(prob_map, threshold=0.1):\n",
    "    body_points = []\n",
    "    \n",
    "    map_gauss = cv2.GaussianBlur(prob_map, (3,3), 0, 0)\n",
    "    map_mask = np.uint8(map_gauss > threshold)\n",
    "    \n",
    "    contours, _ = cv2.findContours(map_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        blob_mask = np.zeros(map_mask.shape)\n",
    "        blob_mask = cv2.fillConvexPoly(blob_mask, c, 1)\n",
    "        masked_prob_map = map_gauss * blob_mask\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(masked_prob_map)\n",
    "\n",
    "        body_points.append(max_loc + (prob_map[max_loc[1], max_loc[0]],))\n",
    "\n",
    "    return body_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key points - Nose : [(145, 170, 0.24120998), (136, 127, 0.4184789), (408, 128, 0.8520362), (329, 75, 0.11857333), (444, 55, 0.26735687), (206, 48, 0.3328478), (171, 48, 0.5133302)]\n",
      "Key points - Neck : [(144, 172, 0.2667331), (391, 161, 0.70504475), (135, 137, 0.4335356), (284, 101, 0.36854365), (451, 65, 0.5178138), (206, 57, 0.66114914), (171, 57, 0.71380293), (681, 31, 0.16509917)]\n",
      "Key points - R-Shoulder : [(162, 179, 0.18160741), (356, 163, 0.68080056), (127, 143, 0.25736088), (286, 74, 0.14741245), (443, 65, 0.48046187), (162, 57, 0.62933254), (205, 57, 0.5204189), (680, 31, 0.109229974)]\n",
      "Key points - R-Elbow : [(320, 215, 0.73568434), (162, 189, 0.15284778), (434, 75, 0.37344542), (197, 73, 0.34908393), (154, 74, 0.47662666), (321, 56, 0.40663266), (74, 13, 0.5823758)]\n",
      "Key points - R-Wrist : [(364, 242, 0.86022645), (162, 189, 0.14159219), (100, 118, 0.44911006), (442, 91, 0.29245332), (154, 83, 0.25816432), (206, 74, 0.21006168), (381, 31, 0.683152)]\n",
      "Key points - L-Shoulder : [(145, 172, 0.18109682), (426, 153, 0.74936527), (144, 143, 0.43869427), (293, 119, 0.3036573), (459, 65, 0.40510046), (180, 64, 0.5749362), (215, 57, 0.58680886), (689, 31, 0.1380588)]\n",
      "Key points - L-Elbow : [(154, 188, 0.13515927), (443, 189, 0.8368428), (295, 171, 0.35444537), (145, 154, 0.19786224), (460, 74, 0.2310473), (181, 74, 0.427709)]\n",
      "Key points - L-Wrist : [(488, 207, 0.62729627), (347, 223, 0.2198557), (214, 74, 0.28424907)]\n",
      "Key points - R-Hip : [(382, 259, 0.60397965), (56, 250, 0.12984118), (222, 198, 0.43575794), (444, 84, 0.33133733), (205, 83, 0.27045986), (162, 84, 0.42415988)]\n",
      "Key points - R-Knee : [(57, 340, 0.23972575), (417, 312, 0.65409404), (214, 303, 0.6962109), (146, 198, 0.1329082), (450, 101, 0.13107426)]\n",
      "Key points - R-Ankle : [(486, 381, 0.65954286), (152, 304, 0.58914644)]\n",
      "Key points - L-Hip : [(433, 250, 0.56446683), (162, 197, 0.11465548), (267, 197, 0.43608266), (452, 84, 0.3405592), (179, 84, 0.38705963), (214, 83, 0.2731524)]\n",
      "Key points - L-Knee : [(452, 321, 0.6649435), (337, 260, 0.6929156), (170, 198, 0.11096997), (452, 101, 0.18547164)]\n",
      "Key points - L-Ankle : [(337, 374, 0.5944097)]\n",
      "Key points - R-Eye : [(144, 163, 0.27799904), (135, 127, 0.41768256), (398, 119, 0.78765786), (443, 49, 0.26632217), (206, 48, 0.31525397), (171, 48, 0.48823094)]\n",
      "Key points - L-Eye : [(145, 163, 0.25640845), (136, 127, 0.35877264), (409, 119, 0.7994978), (444, 48, 0.28697085), (206, 48, 0.3362848), (171, 48, 0.4469941)]\n",
      "Key points - R-Ear : [(144, 163, 0.13314505), (128, 127, 0.25563726), (381, 127, 0.82724243), (206, 48, 0.17929094), (170, 48, 0.31493604)]\n",
      "Key points - L-Ear : [(136, 128, 0.121390745), (417, 119, 0.112248376), (451, 49, 0.28577718), (207, 48, 0.27315387), (178, 48, 0.2716772)]\n"
     ]
    }
   ],
   "source": [
    "frame_width = img_copy.shape[1]\n",
    "frame_height = img_copy.shape[0]\n",
    "in_height = 368\n",
    "in_width = int((in_height/frame_height) * frame_width)\n",
    "\n",
    "pose_model = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "input_blob = cv2.dnn.blobFromImage(img_copy, 1.0/255, (in_width, in_height), (0,0,0), swapRB=False, crop=False)\n",
    "\n",
    "pose_model.setInput(input_blob)\n",
    "output = pose_model.forward()\n",
    "\n",
    "detected_key_points = []\n",
    "key_points_list = np.zeros((0,3))\n",
    "key_point_id = 0\n",
    "\n",
    "for i in range(n_points):\n",
    "    prob_map = output[0,i,:,:]\n",
    "    prob_map = cv2.resize(prob_map, (img_copy.shape[1], img_copy.shape[0]))\n",
    "    body_points = get_key_points(prob_map)\n",
    "    print('Key points - {} : {}'.format(key_points_mapping[i], body_points))\n",
    "    \n",
    "    key_points_with_id = []\n",
    "    for j in range(len(body_points)):\n",
    "        key_points_with_id.append(body_points[j] + (key_point_id,))\n",
    "        key_points_list = np.vstack([key_points_list, body_points[j]])\n",
    "        \n",
    "        key_point_id += 1\n",
    "        \n",
    "    detected_key_points.append(key_points_with_id)\n",
    "    \n",
    "for i in range(n_points):\n",
    "    for j in range(len(detected_key_points[i])):\n",
    "        cv2.circle(img_copy, detected_key_points[i][j][0:2], 5, colors[i], -1, cv2.LINE_AA)\n",
    "        \n",
    "cv2.imshow('Key Points', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_file = './openpose/openpose-master/models/pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt'\n",
    "weight_file = './openpose/openpose-master/models/pose/mpi/pose_iter_160000.caffemodel'\n",
    "\n",
    "frame_width, frame_height = img.shape[1], img.shape[0]\n",
    "in_height = 368\n",
    "in_width = 368\n",
    "\n",
    "pose_net = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "pose_blob = cv2.dnn.blobFromImage(img_copy, scalefactor=1.0/255, size=(in_width, in_height), mean=(0,0,0), swapRB=False, crop=False)\n",
    "pose_net.setInput(pose_blob)\n",
    "output = pose_net.forward()\n",
    "\n",
    "img = cv2.imread('./data/basketball.jpg')\n",
    "img_copy = img.copy()\n",
    "\n",
    "h, w = output.shape[2], output.shape[3]\n",
    "threshold = 0.1\n",
    "n_points = 44 # MPI Pose\n",
    "\n",
    "body_points = []\n",
    "for i in range(n_points):\n",
    "    probs = output[0,i,:,:]\n",
    "    min_val, prob, min_loc, point = cv2.minMaxLoc(probs)\n",
    "    \n",
    "    if prob > threshold:\n",
    "        \n",
    "        x = (frame_width * point[0]) / w\n",
    "        y = (frame_height * point[1]) / h\n",
    "        \n",
    "        cv2.circle(img_copy, (int(x), int(y)), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.putText(img_copy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "        \n",
    "        body_points.append((int(x), int(y)))\n",
    "        \n",
    "    else:\n",
    "        body_points.append(None)\n",
    "        \n",
    "cv2.imshow('Body Points', img_copy)    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
