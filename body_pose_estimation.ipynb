{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_first_frame(path, use_cv2=True):\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if use_cv2:\n",
    "        cv2.imshow('First Frame', frame)\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    else:\n",
    "        new_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(new_frame)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './data/videos/rcpc_bimbambum.mp4'\n",
    "# img = extract_video_first_frame(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_file = './openpose/openpose-master/models/pose/coco/pose_deploy_linevec.prototxt'\n",
    "weight_file = './openpose/openpose-master/models/pose/coco/pose_iter_440000.caffemodel'\n",
    "\n",
    "img = cv2.imread('./data/videos/routine_1.jpg')\n",
    "img_copy = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width, frame_height = img.shape[1], img.shape[0]\n",
    "in_height = 368\n",
    "in_width = 368\n",
    "\n",
    "pose_net = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "pose_blob = cv2.dnn.blobFromImage(img_copy, scalefactor=1.0/255, size=(in_width, in_height), mean=(0,0,0), swapRB=False, crop=False)\n",
    "pose_net.setInput(pose_blob)\n",
    "output = pose_net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "prob_map = output[0,i,:,:]\n",
    "prob_map = cv2.resize(prob_map, (frame_width, frame_height))\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))    \n",
    "plt.imshow(prob_map, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "map_gauss = cv2.GaussianBlur(prob_map, (3,3), 0, 0)\n",
    "map_mask = np.uint8(map_gauss > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(map_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "body_points = []\n",
    "\n",
    "for c in contours:\n",
    "    blob_mask = np.zeros(map_mask.shape)\n",
    "    blob_mask = cv2.fillConvexPoly(blob_mask, c, 1)\n",
    "    masked_prob_map = map_gauss * blob_mask\n",
    "    _, max_val, _, max_loc = cv2.minMaxLoc(masked_prob_map)\n",
    "    \n",
    "    body_points.append(max_loc + (prob_map[max_loc[1], max_loc[0]],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(body_points)):\n",
    "    cv2.circle(img_copy, (body_points[i][0], body_points[i][1]), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "cv2.imshow('Body Points', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 18\n",
    "key_points_mapping = ['Nose', 'Neck', 'R-Shoulder', 'R-Elbow', 'R-Wrist', 'L-Shoulder', 'L-Elbow', 'L-Wrist', 'R-Hip', 'R-Knee', 'R-Ankle',\n",
    "                     'L-Hip', 'L-Knee', 'L-Ankle', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
    "\n",
    "\n",
    "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
    "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
    "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
    "              [2,17], [5,16]]\n",
    "\n",
    "# index of pafs correspoding to the POSE_PAIRS\n",
    "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
    "map_idx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44],\n",
    "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30],\n",
    "          [47,48], [49,50], [53,54], [51,52], [55,56],\n",
    "          [37,38], [45,46]]\n",
    " \n",
    "colors = [[0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
    "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
    "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_points(prob_map, threshold=0.1):\n",
    "    body_points = []\n",
    "    \n",
    "    map_gauss = cv2.GaussianBlur(prob_map, (3,3), 0, 0)\n",
    "    map_mask = np.uint8(map_gauss > threshold)\n",
    "    \n",
    "    contours, _ = cv2.findContours(map_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        blob_mask = np.zeros(map_mask.shape)\n",
    "        blob_mask = cv2.fillConvexPoly(blob_mask, c, 1)\n",
    "        masked_prob_map = map_gauss * blob_mask\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(masked_prob_map)\n",
    "\n",
    "        body_points.append(max_loc + (prob_map[max_loc[1], max_loc[0]],))\n",
    "\n",
    "    return body_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_pairs(output):\n",
    "    \n",
    "    n_inter_samples = 10\n",
    "    paf_threshold = 0.1\n",
    "    conf_threshold = 0.7\n",
    "    \n",
    "    valid_pairs = []\n",
    "    invalid_pairs = []\n",
    "    \n",
    "    for k in range(len(map_idx)):\n",
    "        paf_A = output[0, map_idx[k][0], :, :]\n",
    "        paf_B = output[0, map_idx[k][1], :, :]\n",
    "        paf_A = cv2.resize(paf_A, (frame_width, frame_height))\n",
    "        paf_B = cv2.resize(paf_B, (frame_width, frame_height))\n",
    "        \n",
    "        candidate_A = detected_key_points[POSE_PAIRS[k][0]]\n",
    "        candidate_B = detected_key_points[POSE_PAIRS[k][1]]\n",
    "        len_candidate_A = len(candidate_A)\n",
    "        len_candidate_B = len(candidate_B)\n",
    "        \n",
    "        if len_candidate_A != 0 and len_candidate_B != 0:\n",
    "            valid_pair = np.zeros((0,3))\n",
    "            \n",
    "            for i in range(len_candidate_A):\n",
    "                max_j = -1\n",
    "                max_score = -1\n",
    "                found = False\n",
    "                \n",
    "                for j in range(len_candidate_B):\n",
    "                    d_ij = np.subtract(candidate_B[j][:2], candidate_A[i][:2])\n",
    "                    norm = np.linalg.norm(d_ij)\n",
    "                    if norm:\n",
    "                        d_ij = d_ij / norm\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                    inter_coord = list(zip(np.linspace(candidate_A[i][0], candidate_B[j][0], num=n_inter_samples),\n",
    "                                           np.linspace(candidate_A[i][1], candidate_B[j][1], num=n_inter_samples)))\n",
    "                    \n",
    "                    paf_inter = []\n",
    "                    for k in range(len(inter_coord)):\n",
    "                        paf_inter.append([paf_A[int(round(inter_coord[k][1])), int(round(inter_coord[k][0]))],\n",
    "                                         paf_B[int(round(inter_coord[k][1])), int(round(inter_coord[k][0]))]])\n",
    "                        \n",
    "                    paf_scores = np.dot(paf_inter, d_ij)\n",
    "                    avg_paf_score = sum(paf_scores) / len(paf_scores)\n",
    "                    \n",
    "                    if (len(np.where(paf_scores > paf_threshold)[0]) / n_inter_samples) > conf_threshold:\n",
    "                         if avg_paf_score > max_score:\n",
    "                            max_j = j\n",
    "                            max_score = avg_paf_score\n",
    "                            found = True\n",
    "                                \n",
    "                if found:\n",
    "                    valid_pair = np.append(valid_pair, [[candidate_A[i][3], candidate_B[max_j][3], max_score]], axis=0)\n",
    "                    \n",
    "            valid_pairs.append(valid_pair)\n",
    "        \n",
    "        else:\n",
    "#             print('No connection found: k = {}'.format(k))\n",
    "            invalid_pairs.append(k)\n",
    "            valid_pairs.append([])\n",
    "            \n",
    "    return valid_pairs, invalid_pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_keypoints(valid_pairs, invalid_pairs):\n",
    "    person_wise_keypoints = -1 * np.ones((0,19))\n",
    "    \n",
    "    for k in range(len(map_idx)):\n",
    "        if k not in invalid_pairs:\n",
    "            part_A = valid_pairs[k][:,0]\n",
    "            part_B = valid_pairs[k][:,1]\n",
    "            idx_A, idx_B = np.array(POSE_PAIRS[k])\n",
    "            \n",
    "            for i in range(len(valid_pairs[k])):\n",
    "                found = False\n",
    "                person_idx = -1\n",
    "                for j in range(len(person_wise_keypoints)):\n",
    "                    if person_wise_keypoints[j][idx_A] == part_A[i]:\n",
    "                        person_idx = j\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if found:\n",
    "                    person_wise_keypoints[person_idx][idx_B] = part_B[i]\n",
    "                    person_wise_keypoints[person_idx][-1] += key_points_list[part_B[i].astype(int), 2] + valid_pairs[k][i][2]\n",
    "                    \n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(19)\n",
    "                    row[idx_A] = part_A[i]\n",
    "                    row[idx_B] = part_B[i]\n",
    "                    \n",
    "                    row[-1] = sum(key_points_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2]\n",
    "                    person_wise_keypoints = np.vstack([person_wise_keypoints, row])\n",
    "                    \n",
    "    return person_wise_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key points - Nose : [(428, 304, 0.16684914), (772, 290, 0.8536581)]\n",
      "Key points - Neck : [(694, 431, 0.93203807), (882, 430, 0.68587965), (366, 335, 0.8592197), (771, 322, 0.7742659), (444, 321, 0.9124808), (585, 320, 0.926109)]\n",
      "Key points - R-Shoulder : [(725, 445, 0.771104), (911, 430, 0.5546225), (382, 335, 0.8876237), (741, 321, 0.870254), (460, 320, 0.8522706), (601, 320, 0.82182777)]\n",
      "Key points - R-Elbow : [(912, 462, 0.14081247), (725, 477, 0.29970387), (475, 367, 0.40521777), (397, 367, 0.64675105), (741, 352, 0.74694926), (615, 352, 0.674432)]\n",
      "Key points - R-Wrist : [(446, 367, 0.12943304), (601, 383, 0.22434053), (397, 384, 0.44860998), (615, 336, 0.12264085), (787, 352, 0.8167041)]\n",
      "Key points - L-Shoulder : [(864, 430, 0.5131727), (663, 430, 0.93987864), (788, 335, 0.7987406), (351, 336, 0.78187907), (569, 320, 0.8730605)]\n",
      "Key points - L-Elbow : [(662, 461, 0.10564593), (789, 367, 0.7631901), (413, 367, 0.60636204), (568, 352, 0.5997695)]\n",
      "Key points - L-Wrist : [(568, 383, 0.42711207), (351, 367, 0.2568827), (413, 383, 0.15300703), (757, 352, 0.6224151)]\n",
      "Key points - R-Hip : [(710, 524, 0.6240268), (897, 508, 0.3705153), (742, 399, 0.7979571), (382, 383, 0.82795656), (600, 382, 0.7410608)]\n",
      "Key points - R-Knee : [(913, 508, 0.3122019), (726, 462, 0.7124854), (382, 431, 0.76377463), (600, 430, 0.8675389)]\n",
      "Key points - R-Ankle : [(883, 555, 0.34093896), (695, 556, 0.6487703), (445, 523, 0.6169554), (382, 492, 0.79142874), (600, 477, 0.79324496)]\n",
      "Key points - L-Hip : [(664, 524, 0.63363886), (866, 508, 0.41569284), (773, 399, 0.79962915), (429, 398, 0.7196932), (352, 383, 0.726158), (570, 382, 0.7164036)]\n",
      "Key points - L-Knee : [(663, 524, 0.323786), (788, 476, 0.883294), (366, 444, 0.76162946), (584, 430, 0.7574735)]\n",
      "Key points - L-Ankle : [(678, 571, 0.47659206), (882, 554, 0.18643497), (803, 538, 0.7677939), (445, 523, 0.6328959), (367, 491, 0.65554), (585, 477, 0.8661939)]\n",
      "Key points - R-Eye : [(771, 289, 0.84166616)]\n",
      "Key points - L-Eye : [(428, 290, 0.21950686), (772, 289, 0.90998393)]\n",
      "Key points - R-Ear : [(897, 399, 0.1412278), (711, 399, 0.3831814), (367, 306, 0.4508632), (445, 290, 0.14996769), (757, 290, 0.32763737), (600, 304, 0.4028689)]\n",
      "Key points - L-Ear : [(866, 400, 0.19826297), (679, 399, 0.42154938), (351, 319, 0.48205936), (584, 304, 0.317064), (787, 304, 0.75035936), (429, 290, 0.72277564)]\n",
      "\n",
      "Valid Pairs: [array([[ 2.        ,  8.        ,  0.82758573],\n",
      "       [ 3.        ,  9.        ,  0.60662981],\n",
      "       [ 4.        , 10.        ,  0.87689221],\n",
      "       [ 5.        , 11.        ,  0.8977011 ],\n",
      "       [ 6.        , 12.        ,  0.83309912],\n",
      "       [ 7.        , 13.        ,  0.89332821]]), array([[ 2.        , 26.        ,  0.91153392],\n",
      "       [ 3.        , 25.        ,  0.64266734],\n",
      "       [ 4.        , 28.        ,  0.85699357],\n",
      "       [ 5.        , 27.        ,  0.75858984],\n",
      "       [ 6.        , 28.        ,  0.56292495],\n",
      "       [ 7.        , 29.        ,  0.91783503]]), array([[ 8.        , 15.        ,  0.58757091],\n",
      "       [ 9.        , 14.        ,  0.24818716],\n",
      "       [10.        , 17.        ,  0.82042678],\n",
      "       [11.        , 18.        ,  0.84481815],\n",
      "       [12.        , 16.        ,  0.46785067],\n",
      "       [13.        , 19.        ,  0.70376655]]), array([[17.        , 22.        ,  0.59999028],\n",
      "       [18.        , 24.        ,  0.89264078]]), array([[26.        , 30.        ,  0.21529284],\n",
      "       [27.        , 31.        ,  0.81735829],\n",
      "       [29.        , 33.        ,  0.84920341]]), array([[31.        , 37.        ,  0.71374874],\n",
      "       [32.        , 36.        ,  0.15898495],\n",
      "       [33.        , 34.        ,  0.61822803]]), array([[ 2.        , 38.        ,  0.87310912],\n",
      "       [ 3.        , 39.        ,  0.54806492],\n",
      "       [ 4.        , 41.        ,  0.93229313],\n",
      "       [ 5.        , 40.        ,  0.75923903],\n",
      "       [ 7.        , 42.        ,  0.92839161]]), array([[39.        , 43.        ,  0.22367698],\n",
      "       [40.        , 44.        ,  0.57622911],\n",
      "       [41.        , 45.        ,  0.95151838],\n",
      "       [42.        , 46.        ,  0.95776702]]), array([[43.        , 47.        ,  0.27595804],\n",
      "       [44.        , 48.        ,  0.47467709],\n",
      "       [45.        , 50.        ,  0.94823205],\n",
      "       [46.        , 51.        ,  0.98965899]]), array([[ 2.        , 52.        ,  0.68143077],\n",
      "       [ 3.        , 53.        ,  0.54081859],\n",
      "       [ 4.        , 56.        ,  0.61111846],\n",
      "       [ 5.        , 54.        ,  1.01069291],\n",
      "       [ 6.        , 55.        ,  0.80394125],\n",
      "       [ 7.        , 57.        ,  0.71159715]]), array([[52.        , 58.        ,  0.26620986],\n",
      "       [54.        , 59.        ,  0.82526816],\n",
      "       [56.        , 60.        ,  0.74575355],\n",
      "       [57.        , 61.        ,  0.84036718]]), array([[58.        , 62.        ,  0.45528573],\n",
      "       [59.        , 64.        ,  0.92293371],\n",
      "       [60.        , 66.        ,  0.91962792],\n",
      "       [61.        , 67.        ,  0.97741978]]), array([[5.        , 1.        , 0.96318424],\n",
      "       [6.        , 0.        , 0.15475889]]), array([[ 1.        , 68.        ,  0.90653949]]), array([[68.        , 75.        ,  0.27135375]]), array([[ 0.        , 69.        ,  0.14101861],\n",
      "       [ 1.        , 70.        ,  0.3195492 ]]), array([[69.        , 82.        ,  0.15231992],\n",
      "       [70.        , 81.        ,  0.82894121]]), array([[10.       , 79.       ,  0.2155379]]), array([[27.        , 75.        ,  0.31680888],\n",
      "       [28.        , 73.        ,  0.39827314],\n",
      "       [29.        , 76.        ,  0.26883364]])]\n",
      "Invalid Pairs: []\n"
     ]
    }
   ],
   "source": [
    "img_copy = img.copy()\n",
    "\n",
    "frame_width = img_copy.shape[1]\n",
    "frame_height = img_copy.shape[0]\n",
    "in_height = 368\n",
    "in_width = int((in_height/frame_height) * frame_width)\n",
    "\n",
    "pose_model = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "input_blob = cv2.dnn.blobFromImage(img_copy, 1.0/255, (in_width, in_height), (0,0,0), swapRB=False, crop=False)\n",
    "\n",
    "pose_model.setInput(input_blob)\n",
    "output = pose_model.forward()\n",
    "\n",
    "detected_key_points = []\n",
    "key_points_list = np.zeros((0,3))\n",
    "key_point_id = 0\n",
    "\n",
    "for i in range(n_points):\n",
    "    prob_map = output[0,i,:,:]\n",
    "    prob_map = cv2.resize(prob_map, (img_copy.shape[1], img_copy.shape[0]))\n",
    "    body_points = get_key_points(prob_map)\n",
    "    print('Key points - {} : {}'.format(key_points_mapping[i], body_points))\n",
    "    \n",
    "    key_points_with_id = []\n",
    "    for j in range(len(body_points)):\n",
    "        key_points_with_id.append(body_points[j] + (key_point_id,))\n",
    "        key_points_list = np.vstack([key_points_list, body_points[j]])\n",
    "        \n",
    "        key_point_id += 1\n",
    "        \n",
    "    detected_key_points.append(key_points_with_id)\n",
    "    \n",
    "for i in range(n_points):\n",
    "    for j in range(len(detected_key_points[i])):\n",
    "        cv2.circle(img_copy, detected_key_points[i][j][0:2], 5, colors[i], -1, cv2.LINE_AA)\n",
    "        \n",
    "cv2.imshow('Key Points', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "valid_pairs, invalid_pairs = get_valid_pairs(output)\n",
    "print('\\nValid Pairs:', valid_pairs)\n",
    "print('Invalid Pairs:', invalid_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_wise_keypoints = assign_keypoints(valid_pairs, invalid_pairs)\n",
    "\n",
    "for i in range(17):\n",
    "    for n in range(len(person_wise_keypoints)):\n",
    "        idx = person_wise_keypoints[n][np.array(POSE_PAIRS[i])]\n",
    "        \n",
    "        if -1 in idx:\n",
    "            continue\n",
    "        \n",
    "        B = np.int32(key_points_list[idx.astype(int), 0])\n",
    "        A = np.int32(key_points_list[idx.astype(int), 1])\n",
    "        \n",
    "        cv2.line(img_copy, (B[0], A[0]), (B[1], A[1]), colors[i], 3, cv2.LINE_AA)\n",
    "        \n",
    "cv2.imshow('Bodyline Pose', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path = './data/videos/rcpc_bimbambum.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(vid_path)\n",
    "pose_model = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame_width = frame.shape[1]\n",
    "    frame_height = frame.shape[0]\n",
    "    in_height = 368\n",
    "    in_width = int((in_height/frame_height) * frame_width)\n",
    "    \n",
    "    input_blob = cv2.dnn.blobFromImage(frame, 1.0/255, (in_width, in_height), (0,0,0), swapRB=False, crop=False)\n",
    "\n",
    "    pose_model.setInput(input_blob)\n",
    "    output = pose_model.forward()\n",
    "\n",
    "#     detected_key_points = []\n",
    "#     key_points_list = np.zeros((0,3))\n",
    "#     key_point_id = 0\n",
    "\n",
    "#     for i in range(n_points):\n",
    "#         prob_map = output[0,i,:,:]\n",
    "#         prob_map = cv2.resize(prob_map, (frame.shape[1], frame.shape[0]))\n",
    "#         body_points = get_key_points(prob_map)\n",
    "# #         print('Key points - {} : {}'.format(key_points_mapping[i], body_points))\n",
    "\n",
    "#         key_points_with_id = []\n",
    "#         for j in range(len(body_points)):\n",
    "#             key_points_with_id.append(body_points[j] + (key_point_id,))\n",
    "#             key_points_list = np.vstack([key_points_list, body_points[j]])\n",
    "\n",
    "#             key_point_id += 1\n",
    "\n",
    "#         detected_key_points.append(key_points_with_id)\n",
    "\n",
    "#     for i in range(n_points):\n",
    "#         for j in range(len(detected_key_points[i])):\n",
    "#             cv2.circle(frame, detected_key_points[i][j][0:2], 5, colors[i], -1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Key Points', frame)\n",
    "    \n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#     valid_pairs, invalid_pairs = get_valid_pairs(output)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_file = './openpose/openpose-master/models/pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt'\n",
    "weight_file = './openpose/openpose-master/models/pose/mpi/pose_iter_160000.caffemodel'\n",
    "\n",
    "frame_width, frame_height = img.shape[1], img.shape[0]\n",
    "in_height = 368\n",
    "in_width = 368\n",
    "\n",
    "pose_net = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "pose_blob = cv2.dnn.blobFromImage(img_copy, scalefactor=1.0/255, size=(in_width, in_height), mean=(0,0,0), swapRB=False, crop=False)\n",
    "pose_net.setInput(pose_blob)\n",
    "output = pose_net.forward()\n",
    "\n",
    "img = cv2.imread('./data/basketball.jpg')\n",
    "img_copy = img.copy()\n",
    "\n",
    "h, w = output.shape[2], output.shape[3]\n",
    "threshold = 0.1\n",
    "n_points = 44 # MPI Pose\n",
    "\n",
    "body_points = []\n",
    "for i in range(n_points):\n",
    "    probs = output[0,i,:,:]\n",
    "    min_val, prob, min_loc, point = cv2.minMaxLoc(probs)\n",
    "    \n",
    "    if prob > threshold:\n",
    "        \n",
    "        x = (frame_width * point[0]) / w\n",
    "        y = (frame_height * point[1]) / h\n",
    "        \n",
    "        cv2.circle(img_copy, (int(x), int(y)), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.putText(img_copy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "        \n",
    "        body_points.append((int(x), int(y)))\n",
    "        \n",
    "    else:\n",
    "        body_points.append(None)\n",
    "        \n",
    "cv2.imshow('Body Points', img_copy)    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
