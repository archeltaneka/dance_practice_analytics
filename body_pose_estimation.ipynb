{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_first_frame(path, use_cv2=True):\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if use_cv2:\n",
    "        cv2.imshow('First Frame', frame)\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    else:\n",
    "        new_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(new_frame)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './data/videos/rcpc_bimbambum.mp4'\n",
    "# img = extract_video_first_frame(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_file = './openpose/openpose-master/models/pose/coco/pose_deploy_linevec.prototxt'\n",
    "weight_file = './openpose/openpose-master/models/pose/coco/pose_iter_440000.caffemodel'\n",
    "\n",
    "img = cv2.imread('./data/basketball.jpg')\n",
    "img_copy = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width, frame_height = img.shape[1], img.shape[0]\n",
    "in_height = 368\n",
    "in_width = 368\n",
    "\n",
    "pose_net = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "pose_blob = cv2.dnn.blobFromImage(img_copy, scalefactor=1.0/255, size=(in_width, in_height), mean=(0,0,0), swapRB=False, crop=False)\n",
    "pose_net.setInput(pose_blob)\n",
    "output = pose_net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "prob_map = output[0,i,:,:]\n",
    "prob_map = cv2.resize(prob_map, (frame_width, frame_height))\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB))    \n",
    "plt.imshow(prob_map, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "map_gauss = cv2.GaussianBlur(prob_map, (3,3), 0, 0)\n",
    "map_mask = np.uint8(map_gauss > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(map_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "body_points = []\n",
    "\n",
    "for c in contours:\n",
    "    blob_mask = np.zeros(map_mask.shape)\n",
    "    blob_mask = cv2.fillConvexPoly(blob_mask, c, 1)\n",
    "    masked_prob_map = map_gauss * blob_mask\n",
    "    _, max_val, _, max_loc = cv2.minMaxLoc(masked_prob_map)\n",
    "    \n",
    "    body_points.append(max_loc + (prob_map[max_loc[1], max_loc[0]],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(body_points)):\n",
    "    cv2.circle(img_copy, (body_points[i][0], body_points[i][1]), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "cv2.imshow('Body Points', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_copy = img.copy()\n",
    "n_points = 18\n",
    "key_points_mapping = ['Nose', 'Neck', 'R-Shoulder', 'R-Elbow', 'R-Wrist', 'L-Shoulder', 'L-Elbow', 'L-Wrist', 'R-Hip', 'R-Knee', 'R-Ankle',\n",
    "                     'L-Hip', 'L-Knee', 'L-Ankle', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
    "\n",
    "\n",
    "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
    "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
    "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
    "              [2,17], [5,16]]\n",
    "\n",
    "# index of pafs correspoding to the POSE_PAIRS\n",
    "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44],\n",
    "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30],\n",
    "          [47,48], [49,50], [53,54], [51,52], [55,56],\n",
    "          [37,38], [45,46]]\n",
    " \n",
    "colors = [[0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
    "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
    "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_points(prob_map, threshold=0.1):\n",
    "    body_points = []\n",
    "    \n",
    "    map_gauss = cv2.GaussianBlur(prob_map, (3,3), 0, 0)\n",
    "    map_mask = np.uint8(map_gauss > threshold)\n",
    "    \n",
    "    contours, _ = cv2.findContours(map_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        blob_mask = np.zeros(map_mask.shape)\n",
    "        blob_mask = cv2.fillConvexPoly(blob_mask, c, 1)\n",
    "        masked_prob_map = map_gauss * blob_mask\n",
    "        _, max_val, _, max_loc = cv2.minMaxLoc(masked_prob_map)\n",
    "\n",
    "        body_points.append(max_loc + (prob_map[max_loc[1], max_loc[0]],))\n",
    "\n",
    "    return body_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_pairs(output):\n",
    "    \n",
    "    n_inter_samples = 10\n",
    "    paf_threshold = 0.1\n",
    "    conf_threshold = 0.7\n",
    "    \n",
    "    valid_pairs = []\n",
    "    invalid_pairs = []\n",
    "    \n",
    "    for k in range(len(mapIdx)):\n",
    "        paf_A = output[0, mapIdx[k][0], :, :]\n",
    "        paf_B = output[0, mapIdx[k][1], :, :]\n",
    "        paf_A = cv2.resize(paf_A, (frame_width, frame_height))\n",
    "        paf_B = cv2.resize(paf_B, (frame_width, frame_height))\n",
    "        \n",
    "        candidate_A = detected_key_points[POSE_PAIRS[k][0]]\n",
    "        candidate_B = detected_key_points[POSE_PAIRS[k][1]]\n",
    "        len_candidate_A = len(candidate_A)\n",
    "        len_candidate_B = len(candidate_B)\n",
    "        \n",
    "        if len_candidate_A != 0 and len_candidate_B != 0:\n",
    "            valid_pair = np.zeros((0,3))\n",
    "            \n",
    "            for i in range(len_candidate_A):\n",
    "                max_j = -1\n",
    "                max_score = -1\n",
    "                found = False\n",
    "                \n",
    "                for j in range(len_candidate_B):\n",
    "                    d_ij = np.subtract(candidate_B[j][:2], candidate_A[i][:2])\n",
    "                    norm = np.linalg.norm(d_ij)\n",
    "                    if norm:\n",
    "                        d_ij = d_ij / norm\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                    inter_coord = list(zip(np.linspace(candidate_A[i][0], candidate_B[j][0], num=n_inter_samples),\n",
    "                                           np.linspace(candidate_A[i][1], candidate_B[j][1], num=n_inter_samples)))\n",
    "                    \n",
    "                    paf_inter = []\n",
    "                    for k in range(len(inter_coord)):\n",
    "                        paf_inter.append([paf_A[int(round(inter_coord[k][1])), int(round(inter_coord[k][0]))],\n",
    "                                         paf_B[int(round(inter_coord[k][1])), int(round(inter_coord[k][0]))]])\n",
    "                        \n",
    "                    paf_scores = np.dot(paf_inter, d_ij)\n",
    "                    avg_paf_score = sum(paf_scores) / len(paf_scores)\n",
    "                    \n",
    "                    if (len(np.where(paf_scores > paf_threshold)[0]) / n_inter_samples) > conf_threshold:\n",
    "                         if avg_paf_score > max_score:\n",
    "                                max_j = j\n",
    "                                max_score = avg_paf_score\n",
    "                                found = True\n",
    "                                \n",
    "                if found:\n",
    "                    valid_pair = np.append(valid_pair, [[candidate_A[i][3], candidate_B[max_j][3], max_score]], axis=0)\n",
    "                    \n",
    "            valid_pairs.append(valid_pair)\n",
    "        \n",
    "        else:\n",
    "            print('No connection found: k = {}'.format(k))\n",
    "            invalid_pairs.append(k)\n",
    "            valid_pairs.append([])\n",
    "            \n",
    "    return valid_pairs, invalid_pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key points - Nose : [(407, 127, 0.83688605)]\n",
      "Key points - Neck : [(398, 161, 0.68968636), (276, 110, 0.21944073)]\n",
      "Key points - R-Shoulder : [(356, 163, 0.66799545)]\n",
      "Key points - R-Elbow : [(321, 215, 0.70767957)]\n",
      "Key points - R-Wrist : [(364, 241, 0.830576)]\n",
      "Key points - L-Shoulder : [(433, 154, 0.73351395), (295, 117, 0.1733038)]\n",
      "Key points - L-Elbow : [(444, 198, 0.7231898), (295, 170, 0.1844922)]\n",
      "Key points - L-Wrist : [(347, 223, 0.16195728), (488, 207, 0.55641824)]\n",
      "Key points - R-Hip : [(382, 259, 0.57101864), (215, 198, 0.39895594)]\n",
      "Key points - R-Knee : [(425, 321, 0.62636083), (214, 296, 0.5584647)]\n",
      "Key points - R-Ankle : [(487, 382, 0.6840161), (153, 303, 0.42726678)]\n",
      "Key points - L-Hip : [(433, 250, 0.53099597), (267, 197, 0.40055826)]\n",
      "Key points - L-Knee : [(452, 312, 0.48977676), (337, 259, 0.695864)]\n",
      "Key points - L-Ankle : [(337, 375, 0.55497324)]\n",
      "Key points - R-Eye : [(398, 119, 0.7772169)]\n",
      "Key points - L-Eye : [(409, 119, 0.76513815)]\n",
      "Key points - R-Ear : [(381, 126, 0.7311909)]\n",
      "Key points - L-Ear : [(417, 119, 0.24617639)]\n"
     ]
    }
   ],
   "source": [
    "frame_width = img_copy.shape[1]\n",
    "frame_height = img_copy.shape[0]\n",
    "in_height = 368\n",
    "in_width = int((in_height/frame_height) * frame_width)\n",
    "\n",
    "pose_model = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "input_blob = cv2.dnn.blobFromImage(img_copy, 1.0/255, (in_width, in_height), (0,0,0), swapRB=False, crop=False)\n",
    "\n",
    "pose_model.setInput(input_blob)\n",
    "output = pose_model.forward()\n",
    "\n",
    "detected_key_points = []\n",
    "key_points_list = np.zeros((0,3))\n",
    "key_point_id = 0\n",
    "\n",
    "for i in range(n_points):\n",
    "    prob_map = output[0,i,:,:]\n",
    "    prob_map = cv2.resize(prob_map, (img_copy.shape[1], img_copy.shape[0]))\n",
    "    body_points = get_key_points(prob_map)\n",
    "    print('Key points - {} : {}'.format(key_points_mapping[i], body_points))\n",
    "    \n",
    "    key_points_with_id = []\n",
    "    for j in range(len(body_points)):\n",
    "        key_points_with_id.append(body_points[j] + (key_point_id,))\n",
    "        key_points_list = np.vstack([key_points_list, body_points[j]])\n",
    "        \n",
    "        key_point_id += 1\n",
    "        \n",
    "    detected_key_points.append(key_points_with_id)\n",
    "    \n",
    "for i in range(n_points):\n",
    "    for j in range(len(detected_key_points[i])):\n",
    "        cv2.circle(img_copy, detected_key_points[i][j][0:2], 5, colors[i], -1, cv2.LINE_AA)\n",
    "        \n",
    "cv2.imshow('Key Points', img_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "valid_pairs, invalid_pairs = get_valid_pairs(output)\n",
    "print('\\n Valid Pairs:', valid_pairs)\n",
    "print('Invalid Pairs:', invalid_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_file = './openpose/openpose-master/models/pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt'\n",
    "weight_file = './openpose/openpose-master/models/pose/mpi/pose_iter_160000.caffemodel'\n",
    "\n",
    "frame_width, frame_height = img.shape[1], img.shape[0]\n",
    "in_height = 368\n",
    "in_width = 368\n",
    "\n",
    "pose_net = cv2.dnn.readNetFromCaffe(proto_file, weight_file)\n",
    "pose_blob = cv2.dnn.blobFromImage(img_copy, scalefactor=1.0/255, size=(in_width, in_height), mean=(0,0,0), swapRB=False, crop=False)\n",
    "pose_net.setInput(pose_blob)\n",
    "output = pose_net.forward()\n",
    "\n",
    "img = cv2.imread('./data/basketball.jpg')\n",
    "img_copy = img.copy()\n",
    "\n",
    "h, w = output.shape[2], output.shape[3]\n",
    "threshold = 0.1\n",
    "n_points = 44 # MPI Pose\n",
    "\n",
    "body_points = []\n",
    "for i in range(n_points):\n",
    "    probs = output[0,i,:,:]\n",
    "    min_val, prob, min_loc, point = cv2.minMaxLoc(probs)\n",
    "    \n",
    "    if prob > threshold:\n",
    "        \n",
    "        x = (frame_width * point[0]) / w\n",
    "        y = (frame_height * point[1]) / h\n",
    "        \n",
    "        cv2.circle(img_copy, (int(x), int(y)), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.putText(img_copy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 3, lineType=cv2.LINE_AA)\n",
    "        \n",
    "        body_points.append((int(x), int(y)))\n",
    "        \n",
    "    else:\n",
    "        body_points.append(None)\n",
    "        \n",
    "cv2.imshow('Body Points', img_copy)    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
